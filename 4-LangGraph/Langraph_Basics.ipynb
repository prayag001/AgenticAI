{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import langgraph\n",
    "import langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6cb9c",
   "metadata": {},
   "source": [
    "Langraph, Builtin tools, custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f31125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41274dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_api = WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tool.run({\"query\":\"Narendra Modi\"})  # Example query to test the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efede0e",
   "metadata": {},
   "source": [
    "Custom tool, cyclic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(input1):\n",
    "    return input1+ \" Prayag from first function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(input2):\n",
    "    return input2 + \" Sonar from second function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e483ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function3(input3):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function1(\"prayag sonar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289bcd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1 = StateGraph(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.add_node(\"fun1\", function1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92252b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.add_node(\"fun2\",function2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.add_edge(\"fun1\",\"fun2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.set_entry_point(\"fun1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9084034",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.set_finish_point(\"fun2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a531927",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image,display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbe223",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(\"This will display my graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2044964",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in app.stream(\"stream method invokation\"):\n",
    "    for key, value in output.items():\n",
    "        print(f\"here is the output from {key}\")\n",
    "        print(\"-----------------\")\n",
    "        print(value)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d368f",
   "metadata": {},
   "source": [
    "Another custom too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(input):\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    import os\n",
    "    \n",
    "    model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "    response = model.invoke(input)\n",
    "    \n",
    "    # Return the actual response content\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter(input):\n",
    "    # Count tokens by splitting on whitespace\n",
    "    tokens = input.split()\n",
    "    token_count = len(tokens)\n",
    "    \n",
    "    # You can also count characters for a different metric\n",
    "    char_count = len(input)\n",
    "    \n",
    "    return f\"Response: '{input}'\\nToken count (words): {token_count}\\nCharacter count: {char_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2 = StateGraph(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62655001",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2.add_node(\"My_LLM\", llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6507ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2.add_node(\"LLM_output_token_counter\",token_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88440a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2.add_edge(\"My_LLM\",\"LLM_output_token_counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c245cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2.set_entry_point(\"My_LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2.set_finish_point(\"LLM_output_token_counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0032cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38684667",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76be857",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(\"can you tell me about the india capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(input):\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    import os\n",
    "    \n",
    "    # Make sure to set your Google API key\n",
    "    # os.environ[\"GOOGLE_API_KEY\"] = \"your_api_key_here\"\n",
    "    \n",
    "    model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "    response = model.invoke(input)\n",
    "    \n",
    "    # Return the actual response content\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your Google API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Uncomment and use one of these methods:\n",
    "# Method 1: Set directly (not recommended for production)\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your_api_key_here\"\n",
    "\n",
    "# Method 2: Load from environment file\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# Method 3: Enter securely (recommended for testing)\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter(input):\n",
    "    # Count tokens by splitting on whitespace\n",
    "    tokens = input.split()\n",
    "    token_count = len(tokens)\n",
    "    \n",
    "    # You can also count characters for a different metric\n",
    "    char_count = len(input)\n",
    "    \n",
    "    return f\"Response: '{input}'\\nToken count (words): {token_count}\\nCharacter count: {char_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced token counter using Google's tokenization\n",
    "def advanced_token_counter(input_text):\n",
    "    try:\n",
    "        import google.generativeai as genai\n",
    "        \n",
    "        # Configure with your API key\n",
    "        genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "        \n",
    "        # Create a model instance for token counting\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        \n",
    "        # Count tokens\n",
    "        token_count = model.count_tokens(input_text)\n",
    "        \n",
    "        return f\"Text: '{input_text}'\\nActual tokens (Gemini): {token_count.total_tokens}\\nWord count: {len(input_text.split())}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback to simple word counting\n",
    "        word_count = len(input_text.split())\n",
    "        return f\"Text: '{input_text}'\\nWord count (fallback): {word_count}\\nError: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57839456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the workflow with updated functions\n",
    "workflow2 = StateGraph(dict)\n",
    "workflow2.add_node(\"My_LLM\", llm)\n",
    "workflow2.add_node(\"LLM_output_token_counter\", token_counter)\n",
    "workflow2.add_edge(\"My_LLM\", \"LLM_output_token_counter\")\n",
    "workflow2.set_entry_point(\"My_LLM\")\n",
    "workflow2.set_finish_point(\"LLM_output_token_counter\")\n",
    "\n",
    "# Compile the updated workflow\n",
    "app2 = workflow2.compile()\n",
    "\n",
    "print(\"Workflow recompiled with updated functions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the updated workflow\n",
    "print(\"Testing the updated workflow:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = app2.invoke(\"Can you tell me about India's capital?\")\n",
    "print(\"Final result:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
