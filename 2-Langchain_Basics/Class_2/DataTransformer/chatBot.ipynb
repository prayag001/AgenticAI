{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb528265",
   "metadata": {},
   "source": [
    "Basic LLM powered streamlit app that reads pdf file and replies to specific user's context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef95a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 11:48:04.143 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.357 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Swdtools\\conda_envs\\py311\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-19 11:48:04.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = \"sk-Wr5VzIVOwRoIyzTkQTjiaLQ6lSc84\" #Pass your key here\n",
    "\n",
    "\n",
    "#Upload PDF files\n",
    "st.header(\"My first Chatbot\")\n",
    "\n",
    "\n",
    "with  st.sidebar:\n",
    "    st.title(\"Your Documents\")\n",
    "    file = st.file_uploader(\" Upload a PDf file and start asking questions\", type=\"pdf\")\n",
    "\n",
    "\n",
    "#Extract the text\n",
    "if file is not None:\n",
    "    pdf_reader = PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "        #st.write(text)\n",
    "\n",
    "\n",
    "#Break it into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=150,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    #st.write(chunks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # generating embedding\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "    # creating vector store - FAISS\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "\n",
    "    # get user question\n",
    "    user_question = st.text_input(\"Type Your question here\")\n",
    "\n",
    "\n",
    "    # do similarity search\n",
    "    if user_question:\n",
    "        match = vector_store.similarity_search(user_question)\n",
    "        #st.write(match)\n",
    "\n",
    "\n",
    "        #define the LLM\n",
    "        llm = ChatOpenAI(\n",
    "            openai_api_key = OPENAI_API_KEY,\n",
    "            temperature = 0,\n",
    "            max_tokens = 1000,\n",
    "            model_name = \"gpt-3.5-turbo\"\n",
    "        )\n",
    "\n",
    "\n",
    "        #output results\n",
    "        #chain -> take the question, get relevant document, pass it to the LLM, generate the output\n",
    "        chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "        response = chain.run(input_documents = match, question = user_question)\n",
    "        st.write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
