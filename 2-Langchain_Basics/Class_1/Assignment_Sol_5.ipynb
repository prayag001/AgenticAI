{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pinecone import ServerlessSpec\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG-Chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c195690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"RAG Chatbot with LangChain and Pinecone\")\n",
    "st.markdown(\"This is a demo of RAG Chatbot with LangChain and Pinecone.\")\n",
    "st.markdown(\"You can ask questions about the document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_files = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"], accept_multiple_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45472885",
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploaded_files:\n",
    "    st.write(\"Processing the uploaded files...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bc240",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for uploaded_file in uploaded_files:\n",
    "    #Save the uploaded file to a temporary location\n",
    "    with open(uploaded_file.name, \"wb\") as f:\n",
    "        f.write(uploaded_file.getvalue())\n",
    "    # Load the PDF file\n",
    "    loader = PyMuPDFLoader(uploaded_file.name)\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks= text_splitter.split_documents(docs)\n",
    "st.write(f\"Total chunks created: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9679226",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone vector store\n",
    "pn= Pinecone(pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pn.has_index(\"rag-index\"):\n",
    "    st.write(\"Using existing index 'rag-index'\")\n",
    "    index = pn.Index(\"rag-index\")\n",
    "else:\n",
    "    pn.create_index(\"rag-index\", dimension=768, metric=\"cosine\", \n",
    "                    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n",
    "    index= pn.Index(\"rag-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b02087",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = [str(uuid.uuid4()) for _ in range(len(chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c983fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(documents=chunks, ids=uuids)\n",
    "st.write(\"Documents processed and stored in Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 3, \"score_threshold\": 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RAG Chain\n",
    "from langchain import hub\n",
    "prompt= hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebfedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # User Input Section\n",
    "user_input = st.text_input(\"Ask a question about the document:\")\n",
    "if user_input:\n",
    "    st.write(\"Generating response...\")\n",
    "    response = rag_chain.invoke(user_input)\n",
    "    st.write(\"Response:\")\n",
    "    st.write(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.markdown(\"This is a demo of RAG Chatbot with LangChain and Pinecone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
