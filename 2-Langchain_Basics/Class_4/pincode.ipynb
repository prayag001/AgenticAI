{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a568d9",
   "metadata": {},
   "source": [
    "Multimodal data in vector database, different vector database,PineCone, langchain hub,indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c3d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7b17a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe69c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fd939f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Swdtools\\conda_envs\\py311\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:66\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m embedding = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Swdtools\\conda_envs\\py311\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:68\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mbackend\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33mipex\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_optimum_intel_available() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ipex_available():\n",
      "\u001b[31mImportError\u001b[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.embed_query(\"This is a test query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043486d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Initialize embeddings\n",
    "google_embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_embedding.embed_query(\"This is a test query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47256f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pine_cone_api = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pine_cone_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1fc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1150e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pinecone_index= \"my-pinecone-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17334562",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.create_index(name=my_pinecone_index,\n",
    "                dimension=768,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud=\"aws\",\n",
    "                    region=\"us-east-1\",\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index= pc.Index(my_pinecone_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2332c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_vector_store = PineconeVectorStore(\n",
    "    index=pinecone_index,\n",
    "    embedding=google_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca537098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec610dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4 \n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc20744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_vector_store.add_documents(documents=documents,uuids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pinecone_vector_store.similarity_search(\"what is langchain?\", filter={\"source\": \"tweet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35da6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_retriever = pinecone_vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f4f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='66fcd1eb-f04a-4ca5-a23d-87d74b76d88e', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(id='91e9cbee-e051-4d79-aa8e-356992f5d71d', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_retriever.invoke(\n",
    "    \"What is the best framework for building stateful, agentic applications?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e3311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "google_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab644c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt=hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c475fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93124dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_prompt= PromptTemplate(\n",
    "    template=\"You are an assistant that answers questions based on the provided context.\\n\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556adda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is the best framework for building stateful, agentic applications? \\nContext: langchain \\nAnswer:\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the best framework for building stateful, agentic applications?\",\n",
    "        \"context\": \"langchain\"},\n",
    "    output_parser=StrOutputParser(),\n",
    "    run_manager=RunnablePassthrough()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": pinecone_retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | pinecone_prompt\n",
    "    | google_model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64163ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided text does not contain information about LLMs (Large Language Models).  Therefore, I cannot answer your question based on the given context.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is llm model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rag_chain(question: str) -> str:\n",
    "    # Get relevant documents from Pinecone\n",
    "    retrieved_docs = pinecone_retriever.invoke(question)\n",
    "    \n",
    "    # Extract and format the context from retrieved documents\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # Format the prompt with context and question\n",
    "    formatted_prompt = pinecone_prompt.format(\n",
    "        context=context,\n",
    "        question=question\n",
    "    )\n",
    "    \n",
    "    # Get response from the model\n",
    "    response = google_model.invoke(formatted_prompt)\n",
    "    \n",
    "    # Parse and return the final answer\n",
    "    return StrOutputParser().invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c05985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, LangGraph is the best framework for building stateful, agentic applications.  The text doesn't specify if this makes it the *best* for all AI applications, only those that are stateful and agentic.\n"
     ]
    }
   ],
   "source": [
    "# Test the custom RAG chain\n",
    "result = custom_rag_chain(\"What is the best framework for building AI applications?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
